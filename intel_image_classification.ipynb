{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Velociraptorvelraptor/pytorch-lightening-intel-img-classification/blob/main/intel_image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBuhmY9vQZXk"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /root/.kaggle "
      ],
      "metadata": {
        "id": "rkN8a8G2Q4iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/kaggle.json /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Z241Lzi3Q55L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cqRTBBuZGP-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d puneet6060/intel-image-classification"
      ],
      "metadata": {
        "id": "42_vPKeBDPlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/intel-image-classification.zip '/content/drive/MyDrive/Colab Notebooks/intel-image-classification'"
      ],
      "metadata": {
        "id": "dxrVM3NODjZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/Colab Notebooks/intel-image-classification/intel-image-classification.zip' -d '/content/drive/MyDrive/Colab Notebooks/intel-image-classification/data'\n",
        "\n"
      ],
      "metadata": {
        "id": "nqS0QliXQ7S6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_path = '/content/drive/MyDrive/Colab Notebooks/intel-image-classification'"
      ],
      "metadata": {
        "id": "8NSvkppKG6PZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = src_path + '/data/seg_train/seg_train/'\n",
        "test_path = src_path + '/data/seg_test/seg_test/'"
      ],
      "metadata": {
        "id": "QktKH0z8RIhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path"
      ],
      "metadata": {
        "id": "gG9KULU9HFIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning==1.8.5 torchvision torchmetrics"
      ],
      "metadata": {
        "id": "azbhoPrEt02m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from types import SimpleNamespace\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import random_split\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "from torchmetrics.classification import MulticlassAccuracy\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchmetrics import ConfusionMatrix, F1Score, ROC\n"
      ],
      "metadata": {
        "id": "UZG5L_AeRbTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = T.Compose([T.ToTensor(), \n",
        "                       T.Resize((64, 64)),\n",
        "                       T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ],
      "metadata": {
        "id": "mb5WGGRuq8bV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ImageFolder(train_path, transform)\n",
        "test_dataset = ImageFolder(test_path, transform)"
      ],
      "metadata": {
        "id": "R8M5yBCpp0Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "IRaJ1z7KH-iR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = train_dataset[3]; img.shape"
      ],
      "metadata": {
        "id": "DGlDOddkrGrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def img_display(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    npimg = np.transpose(npimg, (1, 2, 0))\n",
        "    return npimg"
      ],
      "metadata": {
        "id": "KBc69txerMvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_idx = int(len(train_dataset) * 0.8)\n",
        "val_idx = len(train_dataset) - train_idx"
      ],
      "metadata": {
        "id": "GyVjHwatrh-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, val_dataset = random_split(train_dataset, [train_idx, val_idx])"
      ],
      "metadata": {
        "id": "86vkxD_LTbba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_img, sample_label = val_dataset.__getitem__(0)\n",
        "\n",
        "plt.imshow(img_display(sample_img))\n",
        "plt.title(f'Encoded label: {sample_label}')"
      ],
      "metadata": {
        "id": "RsvKpKdCrXDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "S1-Q-RUetPgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_dataset, BATCH_SIZE, shuffle=True)\n",
        "val_dl = DataLoader(val_dataset, BATCH_SIZE, shuffle=True)\n",
        "test_dl = DataLoader(test_dataset, BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "uCfzdhOctJZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _conv_block(in_channels, out_channels, pool=False):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
        "              nn.BatchNorm2d(out_channels), \n",
        "              nn.ReLU(inplace=True)]\n",
        "    if pool: layers.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class LitModel(pl.LightningModule):\n",
        "    def __init__(self, in_channels=3, num_classes=6, learning_rate=1e-3):\n",
        "        super().__init__()\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_classes = num_classes\n",
        "        self.train_accuracy = MulticlassAccuracy(self.num_classes)\n",
        "        self.val_accuracy = MulticlassAccuracy(self.num_classes)\n",
        "        self.test_accuracy = MulticlassAccuracy(self.num_classes)\n",
        "        self.confmat = ConfusionMatrix(task=\"multiclass\", num_classes=self.num_classes)\n",
        "        self.f1 = F1Score(task=\"multiclass\", num_classes=self.num_classes)\n",
        "        self.roc = ROC(task=\"multiclass\", num_classes=self.num_classes)\n",
        "\n",
        "                # Define PyTorch model\n",
        "        self.conv1 = _conv_block(in_channels, 64)\n",
        "        self.conv2 = _conv_block(64, 128, pool=True)\n",
        "        self.res1 = nn.Sequential(_conv_block(128, 128), _conv_block(128, 128))\n",
        "        \n",
        "        self.conv3 = _conv_block(128, 256, pool=True)\n",
        "        self.conv4 = _conv_block(256, 512, pool=True)\n",
        "        self.res2 = nn.Sequential(_conv_block(512, 512), _conv_block(512, 512))\n",
        "        \n",
        "        self.classifier = nn.Sequential(nn.AdaptiveMaxPool2d(1), \n",
        "                                        nn.Flatten(), \n",
        "                                        nn.Dropout(0.2),\n",
        "                                        nn.Linear(512, self.num_classes))\n",
        "\n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.res1(out) + out\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.res2(out) + out\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = nn.functional.cross_entropy(logits, y)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        self.train_accuracy.update(preds, y)\n",
        "        self.log(\"train_loss\", loss, prog_bar=True, on_epoch=True)\n",
        "        self.log(\"train_acc\", self.train_accuracy, prog_bar=True, on_epoch=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = nn.functional.cross_entropy(logits, y)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        self.val_accuracy.update(preds, y)\n",
        "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True)\n",
        "        self.log(\"val_acc\", self.val_accuracy, prog_bar=True, on_epoch=True)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        acc_list = []\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = nn.functional.cross_entropy(logits, y)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        self.test_accuracy.update(preds, y)\n",
        "        self.confmat.update(preds, y)\n",
        "        self.f1.update(preds, y)\n",
        "        # Calling self.log will surface up scalars for you in TensorBoard\n",
        "        self.log(\"test_loss\", loss, on_epoch=True)\n",
        "        self.log(\"test_acc\", self.test_accuracy, on_epoch=True)\n",
        "        self.log(\"f1\", self.f1, on_epoch=True)\n",
        "\n",
        "    def on_test_end(self):\n",
        "        cm_tensor = self.confmat.compute()\n",
        "        fig = plt.figure(figsize=[10,10])\n",
        "        plt.title(f\"Confusion matrix\")\n",
        "        sns.heatmap(cm_tensor.cpu().numpy(), annot=True, cmap='Blues')\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer"
      ],
      "metadata": {
        "id": "_W5fZpBjACeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LitModel(); model"
      ],
      "metadata": {
        "id": "VwECZZJriz8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(auto_lr_find=True, gpus=-1, limit_train_batches=0.1)\n",
        "lr_finder = trainer.tuner.lr_find(model, train_dataloaders=train_dl)"
      ],
      "metadata": {
        "id": "wmrT12-qt85v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot with\n",
        "fig = lr_finder.plot(suggest=True)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "-DFueYonuAK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_lr = lr_finder.suggestion()\n",
        "\n",
        "# update hyperparams of the model\n",
        "model.learning_rate = new_lr"
      ],
      "metadata": {
        "id": "aMrVmGf52tmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback = ModelCheckpoint(dirpath=src_path + '/checkpoints/', save_top_k=2, monitor=\"val_loss\")"
      ],
      "metadata": {
        "id": "lBUMbg1HPaXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(\n",
        "    accelerator=\"auto\",\n",
        "    devices=1 if torch.cuda.is_available() else None,  # limiting got iPython runs\n",
        "    max_epochs=50,\n",
        "    logger=CSVLogger(save_dir=\"logs/\"),\n",
        "    limit_train_batches=0.2,\n",
        "    limit_val_batches=0.05,\n",
        "    callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "id": "7UNkT4EJAbLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model, train_dl, val_dl)"
      ],
      "metadata": {
        "id": "PkX_HtMXN-YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = pd.read_csv(f\"{trainer.logger.log_dir}/metrics.csv\")\n",
        "del metrics[\"step\"]\n",
        "metrics.set_index(\"epoch\", inplace=True)\n",
        "display(metrics.dropna(axis=1, how=\"all\").head())\n",
        "sns.relplot(data=metrics, kind=\"line\")"
      ],
      "metadata": {
        "id": "VlpWLq5zAbOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LitModel.load_from_checkpoint(checkpoint_path= src_path + \"/checkpoints/epoch=9-step=350.ckpt\")"
      ],
      "metadata": {
        "id": "zFLQd-1SryRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(model, test_dl, ckpt_path=src_path + \"/checkpoints/epoch=9-step=350.ckpt\")"
      ],
      "metadata": {
        "id": "AuxW1pnvtv6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UtnyglQ1NnrO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}